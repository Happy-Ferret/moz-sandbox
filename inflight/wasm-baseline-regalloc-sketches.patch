# HG changeset patch
# User Lars T Hansen <lhansen@mozilla.com>
# Date 1462267805 -7200
#      Tue May 03 11:30:05 2016 +0200
# Node ID d8102af67c12fefa7ed89750b148e25c57b65476
# Parent  dbb044f8be8af8b5842de322abd4749f09c35354
Sketches for better register allocation, not operational

diff --git a/js/src/asmjs/WasmBaselineCompile.cpp b/js/src/asmjs/WasmBaselineCompile.cpp
--- a/js/src/asmjs/WasmBaselineCompile.cpp
+++ b/js/src/asmjs/WasmBaselineCompile.cpp
@@ -2443,41 +2443,108 @@ class FunctionCompiler
     bool emitSimdCtor(ValType type);
     bool unimplemented(const char* msg);
     bool unimplementedBinop();
     bool unimplementedUnop();
     bool unimplementedConversion();
 
     //////////////////////////////////////////////////////////////////////
 
+    // Flight of fancy: register allocation abstraction
+    //
+    // While these nodes are live they keep their registers live, they will not
+    // be allocated for other purposes.  This works well because of the
+    // non-recursive decoding / because we allocate only at the leaves and
+    // propagate results from a stack.  Anyway, this means NeedI need not take
+    // any popped registers as arguments because it is already known that those
+    // registers cannot be allocated.
+    //
+    // The only registers that can be allocated are those that are free and
+    // those that are used for values that are on the stack.
+
+    // For simplicity, registers are named uniformly left-to-right: r0, r1, and
+    // so on.  There are accessors for the underlying hardware registers,
+    // g0(), g1(), f0(), f1(), etc.
+
+    // Bug: these do not have access to FunctionCompiler...  So maybe we want:
+    //
+    // Regs x(pop2I())  // where pop2I() returns a struct of some sort and Regs is templated by type
+    // ...
+    // pushR0(x)        // which is statically dispatched because of template type
+
+
+    struct PopI {
+        PopI() : r0(I0) { popI(); }
+        IReg r0;
+        Register g0() { return r0.reg; }
+        void pushR0() { pushI(r0); }
+    };
+
+    struct Pop2I {
+        Pop2I() : r0(I0), r1(I1) { pop2I(); }
+        IReg r0;
+        IReg r1;
+        Register g0() { return r0.reg; }
+        Register g1() { return r1.reg; }
+        void pushR0() { pushI(r0); }
+    };
+
+    struct NeedI {
+        NeedI() : r0(I0) { needI0(); }
+        IReg r0;
+        Register g0() { return r0.reg; }
+        void pushR0() { pushI(r0); }
+    };
+
+    // convention: r0 is leftmost
+
+    struct I2 {
+        I2() {}
+        I2(const I2& other) : r0(other.r0), r1(other.r1) {}
+        I2(IReg r0, IReg r1) : r0(r0), r1(r1) {}
+        IReg r0, r1;
+        Register g0() { return r0.reg; }
+        Register g1() { return r1.reg; }
+    };
+
+    I2 pop2I() {
+        I2 xs(I0, I1);
+        pop2I();
+        return xs;
+    }
+
+    void freeI(IReg r) {
+        // Nothing yet
+    }
+
+    //////////////////////////////////////////////////////////////////////
+
     // There are some obvious patterns below that we could package in
     // various ways, but let's not do that until we see what the code
     // looks like once (a) some of the code above has been moved into
     // the MacroAssembler and (b) we've reconsidered register
     // management.
 
     bool emitAddI() {
         int32_t c;
         if (popConstI(c)) {
-            popI();
-            masm.add32(Imm32(c), I0.reg);
+            IReg x(popI());
+            masm.add32(Imm32(c), x.reg);
+            pushI(x);
         } else {
-            // TODO: For integer addition and equality there is a
-            // notion of a "pop2ICommutative" where it doesn't matter
-            // if we get (I0, I1) or (I1, I0); it may reduce value
-            // shuffling.
-            pop2I();
-            masm.add32(I1.reg, I0.reg);
+            I2 xs(pop2I());
+            masm.add32(xs.g1(), xs.g0());
+            pushI(xs.r0);
+            freeI(xs.r1);
         }
-        pushI(I0);
         return true;
     }
 
     bool emitAddX() {
-        // Ditto check for constant here
+        // Ditto check for constant here, at least on 64-bit systems
         pop2X();
         masm.add64(X1.reg, X0.reg);
         pushX(X0);
         return true;
     }
 
     bool emitAddD() {
         // Ditto check for constant here, since there's a MASM op for addDoubleConstant.
@@ -2491,19 +2558,19 @@ class FunctionCompiler
         // Ditto check for constant here, since there's a MASM op for addDoubleConstant.
         pop2F();
         addF(F1, F0);
         pushF(F0);
         return true;
     }
 
     bool emitSubI() {
-        pop2I();                // i1 is rhs, i0 is lhs
-        masm.sub32(I1.reg, I0.reg);
-        pushI(I0);
+        Pop2I xs;
+        masm.sub32(xs.g1(), xs.g0());
+        xs.pushR0();
         return true;
     }
 
     bool emitSubX() {
         pop2X();
         subX(X1, X0);
         pushX(X0);
         return true;
@@ -2519,19 +2586,19 @@ class FunctionCompiler
     bool emitSubD() {
         pop2D();
         masm.subDouble(D1.reg, D0.reg);
         pushD(D0);
         return true;
     }
 
     bool emitMulI() {
-        pop2I();
-        mulI(I1, I0);
-        pushI(I0);
+        Pop2I xs;
+        mulI(xs.r1, xs.r0);
+        xs.pushR0();
         return true;
     }
 
     bool emitMulX() {
         pop2X();
         mulX(X1, X0);
         pushX(X0);
         return true;
@@ -3643,16 +3710,17 @@ FunctionCompiler::emitGetLocal()
         break;
       case ValType::F64:
         pushLocalD(slot);
         break;
       case ValType::F32:
         pushLocalF(slot);
         break;
       default:
+        pushVoid();
         return unimplemented("local var type");
     }
 
     return true;
 }
 
 bool
 FunctionCompiler::emitSetLocal()
@@ -3704,37 +3772,39 @@ FunctionCompiler::emitGetGlobal()
 {
     if (!iter_.readGetGlobal(mg_.globals))
         return false;
 
     const GetVarRecord& getVar = iter_.getVar();
     const GlobalDesc& global = mg_.globals[getVar.id];
 
     switch (global.type) {
-      case ValType::I32:
-        needI0();
-        loadGlobalVarI(global.globalDataOffset, I0);
-        pushI(I0);
+      case ValType::I32: {
+        NeedI r;
+        loadGlobalVarI(global.globalDataOffset, r.g0());
+        r.pushR0();
         break;
+      }
       case ValType::I64:
         needX0();
         loadGlobalVarX(global.globalDataOffset, X0);
         pushX(X0);
         break;
       case ValType::F32:
         needF0();
         loadGlobalVarF(global.globalDataOffset, F0);
         pushF(F0);
         break;
       case ValType::F64:
         needD0();
         loadGlobalVarD(global.globalDataOffset, D0);
         pushD(D0);
         break;
       default:
+        pushVoid();
         unimplemented("Global variable type");
         break;
     }
     return true;
 }
 
 bool
 FunctionCompiler::emitSetGlobal()
@@ -3787,16 +3857,17 @@ FunctionCompiler::emitLoad(ValType type,
 
     switch (type) {
       case ValType::I32:
         popI();
         loadHeap(access, I0, AnyReg(I0));
         pushI(I0);
         break;
       case ValType::I64:
+        pushVoid();
         unimplemented("loadHeap i64"); // Also not in WasmIonCompile, we don't have the infrastructure
         break;
       case ValType::F32:
         popI();
         needF0();
         loadHeap(access, I0, AnyReg(F0));
         pushF(F0);
         break;
@@ -4109,16 +4180,17 @@ FunctionCompiler::emitStoreWithCoercion(
 }
 
 bool
 FunctionCompiler::emitAtomicsLoad()
 {
     if (!iter_.readAtomicLoad())
         return false;
 
+    pushVoid();
     return unimplemented("atomic load");
 /*
     const AtomicLoadRecord<MDefinition*>& atomicLoad = iter_.atomicLoad();
 
     MAsmJSHeapAccess access(atomicLoad.viewType, 0, MembarBeforeLoad, MembarAfterLoad);
     access.setOffset(atomicLoad.addr.offset);
     access.setAlign(atomicLoad.addr.align);
 
