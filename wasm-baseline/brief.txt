How does wasm code expose itself to JS?  Is it like asm as a module
that is invoked to produce a set of entry points?  If so, how is that
module represented to the JS pipeline - as a new thing, or as a JS
function with a magic directive, or something else?

Since asm.js translates to wasm, assume we can start experimenting
with the baseline by hooking into the asm.js pipeline and providing a
baseline compiler for asm.js.  This means that the "finish function"
machinery at the asm/wasm interface just needs a flag about the type
of compilation desired, or, the type desired is always baseline, with
ion "always" being triggered by baseline profiling.  (Probably both,
consider eg "--ion-asm-eager".)

That probably means abstracting FunctionCompiler a little bit, or
wasm's ModuleGenerator's interface to CompileFunction (it would use a
different CompileFunction that is compatible with the existing one.)

The fact that we're compiling transliterated asm.js is not a concern
at present, we just want to get the baseline up and running quickly.

----------------------------------------

Keep all locals on the stack, including parameters.  Each local has a
designated home location.

Follow asm.js on its ABI usage and other conventions whenever
possible, hopefully always.

If the ABI passes any parameters in registers then spill these to the
appropriate stack location on entry.

We might need a map from local index to frame location since locals
can have different sizes etc.

How do we access the frame?  Frame pointer?  When we generate the code
we won't know the frame size so an SP-relative reference will have to
be backpatched /or/ we put all locals at the SP with spill slots above
locals.  (This means copying parameters that come in on the stack,
which is not great, but neither is a frame pointer or patching.)  Then
everything is SP-relative.

Do we need to save any registers on entry (ie callee-saves registers
in the ABI?)

Proper spill/restore requires that control flow does not cross a
restore point if the value might be needed at the branch target
(almost always).  This is important, and probably hard to verify
statically, but essentially, no branch instruction may take place out
of a block containing a Defn that might have caused spilling.  Ouch!
We will need a branchIfFalseWithRestore() type operation for this, ie,
the defn needs to track whatever was spilled to make room for it and
restore it after testing.

In some sense we can make that solid by /always/ requiring an explicit
restore operation at the end of a block.  Then if a Defn goes out of
scope while still being flagged as having caused a spill, we can
statically error out.  This could just be a restore() method on the
Defn.  Consider add:

static bool
EmitAdd(FunctionCompiler& f, ValType type, Defn& dest)
{
    if (!EmitExpr(f, type, dest))
        return false;
    Defn rhs(f, type, Needed(dest));
    if (!EmitExpr(f, type, rhs))
        return false;
    f.add(dest, rhs, ToMIRType(type));
    rhs.restore();    <=================== clear us for exit
    return true;
}

For occasional cases we /may/ want rhs.clear() instead, eg, this /may/
be appropriate for return, I'm not sure yet.  (Probably not, in fact.)

Also: switchDispatchAndRestore().

----------------------------------------

Obvious steps:

1a) Code generator that keeps locals on the stack in a predictable way
   and always loads/stores upon use, register allocation is only
   needed for deep expressions (if we have them) and for callouts, and
   can be greedy.  Arguments passed on the stack, or spilled
   immediately on entry.  Very basic instruction selection, use masm
   and extend platform-independent masm API as necessary to avoid
   dropping into platform code very often. Look to the JS baseline
   compiler for ideas too.

   When there needs to be platform priority, give it to x64 first?

   Obviously should just copy WasmIonCompile.cpp and use that as a
   basis.

*) Validate that this works on all code before going further.

1b) Presumably we also need profiling here to drive Ion compilation,
   and either OSR or some other type of hot-patching eg indirect calls
   as Luke suggested.  Also interrupt checks in some fashion.

TODO: Construct full list of features so that we can stage things
      appropriately.

*) Again

2a) Start work on debugger thing, so that when we do register allocation
    next we can get it right for its needs.

2b) Code generator adds extended basic block allocation, where values
   are lifted into registers as needed (joins are tricky but perhaps
   they are not EBBs then), spilled to their home locations when the
   register is needed or the block ends and the value is dirty.
   Spilling needs to be driven by some heuristic, initially this can
   be LRU and we don't need any forward context.  Break EBBs at calls
   where registers have to be spilled anyhow.  As special case, the
   first EBB has live-in registers (the arguments) and we allocate
   values in registers for some arguments.  Look to the JS baseline
   compiler for ideas too, it must need something similar.

*) Again

3) Full OSR?  If we OSR at back-edges where locals are by definition
   spilled to their home locations we should be fine, largely.

*) Again

...

m) General instruction selection improvements, incrementally, now that
   register allocation is non-dumb.

n) Improve the spilling heuristic, build a Def-Use chain to compute
   furthest future use perhaps.  Also take into account desirable
   location for calls.  (Probably there is vast literature here.)  Not
   obvious that this will be worth it, given that Ion will take care
   of hot code.

----------------------------------------

Some notes removed from the code for the postorder decoder.

// Stack must be typed - probably there are multiple stacks?  Or how do we handle alignment?
// Stack has both values and control items - or more likely there's a separate control stack?
// Note, run-time stack and compile-time stack are different, latter must record offsets in
//  former but run-time stack needs no control items (isn't really a stack at all, just a
//  memory area)
// Stack types at compile time are used to check operand types.
// A branch ends up search the compile stack for a control item and then pops the stack
//  and optionally pushes the value
// A simple peephole optimizer could quash push/pop pairs or turn them into MOVs
// Probably less effective than a register allocator though

// Registers are I0, I1, ..., X0, X1, ..., F0, F1, ..., D0, D1, ...
// Use this convention throughout to abbreviate names.


// Register allocation.
//
// At the moment we allocate only expression values in registers, not
// locals or parameters.  We maintain a stack of unconsumed values,
// this mirrors (and is implemented by) the iterator's stack.  Each
// new value pushed onto the stack is allocated to a register.  If we
// run out of registers, values at the bottom of the stack are spilled
// to memory, where they will henceforth remain.  When a value is
// about to be consumed it may be re-loaded into a register if it has
// been spilled.
//
// Spill code generation is still tricky: the value needs to be
// spilled along all control flow paths *or* it needs to be restored
// to its home register on control flow out of a spilled region, but
// that conflicts with allocating the register deep and returning it,
// which we need to do for untyped operations (blocks, loops).
//
// This mechanism works because a value on the stack is only ever
// consumed once.  There is no need to "unspill" a value at the point
// where it was spilled, ...
//
// When the stack is popped the consumed registers are freed: this is
// true for operators as well as branches (which "consume" the unused
// operands between the branch source and target).


// Suppose we build simple trees.  These can be allocated on a custom
// stack, and we can pop them when we consume them, but as the bug in
// the iterator shows, we may not know that for a long time.  So we
// may end up having a lot of data around, which is bad.
//
// The purpose of the tree would be to provide surrounding context when
// we generate code for the subtrees: we will know the type of the value
// and we will know how the value will be consumed and the consumer
// of the values will know their general shapes (enabling simple optimizations).

// The regular baseline jit instead uses a frame stack, where the topmost
// values are not evaluated until something happens to force that.  For
// constants and simple operators that probably works well, though the
// stack is a Value stack, and there is only one type of Value.  We have
// fewer constant ops but more types.

// Suppose for v0.1 we have a true value stack and that for labeled
// phrases we always pop the stack back to some known stack pointer.
//
// We never need to "push" and "pop", we'll always know the frame offsets
// of the operands.
//
// We still suffer from the the failure to consume dead values but
// let's ignore that for now.  It'll just result in large frames and
// dead stack stores.

// Stage 0 register allocation:
//
// There are dedicated RESULT registers, one for each type.  The I32 and I64
// registers may overlap, as may the and F32 and F64 registers.
//
// Constants are computed into RESULT.
// Locals are loaded into RESULT.
// Expressions (primitive operations) are computed into RESULT.
//
// A value-carrying operation always leaves the value in RESULT.  This includes
// control flow operations.  It is the consumer that determines what to do
// with the value.
//
// If the consumer cannot use the value immediately, it will always spill it,
// and then restore it to RESULT or SECOND when needed.  (In reality,
// it can almost never tell if it will consume it right away, because of
// postorder, so it will effectively always have to spill everything.)
//
// Spilling is on a stack, each expression in the program has a statically
// allocated stack location where it will spill.  The frame is pre-allocated.


